#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —á–µ—Ä–µ–∑ Scrapy.
"""

import os
import sys
import json
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime


def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫."""
    required = ['scrapy', 'pandas', 'matplotlib', 'psutil']
    missing = []
    
    for lib in required:
        try:
            __import__(lib)
        except ImportError:
            missing.append(lib)
    
    if missing:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {', '.join(missing)}")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–æ–π: pip install scrapy pandas matplotlib psutil")
        return False
    return True


def create_directories():
    """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
    directories = [
        'graphs/load_testing',
        'graphs/exploratory_analysis',
        'graphs/technologies',
        'data'
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
    
    print("‚úÖ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–æ–∑–¥–∞–Ω—ã")


def extract_technologies(vacancy_name, vacancy_snippet):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏."""
    tech_keywords = {
        'Python': ['python'],
        'Django –∏ –¥—Ä.': ['django', 'flask', 'fastapi'],
        'JavaScript': ['javascript', 'js', 'node.js', 'nodejs'],
        'React –∏ –¥—Ä.': ['react', 'vue', 'angular'],
        'Java': ['java', 'hibernate'],
        'Spring': ['spring'],
        'C++': ['c++', 'cpp'],
        'C# & .NET': ['c#', 'csharp', '.net'],
        'PHP': ['php', 'laravel', 'symfony'],
        'Go': ['go', 'golang'],
        'Ruby': ['ruby', 'rails'],
        'SQL': ['sql', 'mysql', 'postgresql', 'oracle'],
        'NoSQL': ['mongodb', 'redis', 'cassandra'],
        'Docker': ['docker', 'container'],
        'Kubernetes': ['kubernetes', 'k8s'],
        'AWS': ['aws', 'amazon web services'],
        'Azure': ['azure'],
        'Git': ['git', 'github', 'gitlab'],
        'Linux': ['linux', 'unix']
    }
    
    found_tech = set()
    text = f"{vacancy_name} {vacancy_snippet}".lower()
    
    for tech, keywords in tech_keywords.items():
        for keyword in keywords:
            if keyword in text:
                found_tech.add(tech)
                break
    
    return list(found_tech)


def analyze_vacancies(filename="programming_vacancies.json"):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏."""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            vacancies = json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
        return pd.DataFrame(), pd.Series()
    
    print(f"üìä –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(vacancies)}")
    
    df_data = []
    all_technologies = []
    
    for vac in vacancies:
        # –ó–∞—Ä–ø–ª–∞—Ç–∞
        salary = vac.get('salary')
        avg_salary = None
        if salary:
            salary_from = salary.get('from')
            salary_to = salary.get('to')
            if salary_from and salary_to:
                avg_salary = (salary_from + salary_to) / 2
            elif salary_from:
                avg_salary = salary_from
            elif salary_to:
                avg_salary = salary_to
        
        # –û–ø—ã—Ç
        experience = vac.get('experience', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω')
        
        # –ó–∞–Ω—è—Ç–æ—Å—Ç—å
        employment = vac.get('employment', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
        
        # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        snippet = vac.get('snippet', {})
        requirement = snippet.get('requirement', '') or ''
        responsibility = snippet.get('responsibility', '') or ''
        vacancy_snippet = f"{requirement} {responsibility}"
        
        technologies = extract_technologies(vac.get('name', ''), vacancy_snippet)
        all_technologies.extend(technologies)
        
        df_data.append({
            'id': vac.get('id', ''),
            'name': vac.get('name', ''),
            'salary_avg': avg_salary,
            'experience': experience,
            'employment': employment,
            'area': vac.get('area', {}).get('name', ''),
            'published_at': vac.get('published_at', ''),
            'technologies': technologies
        })
    
    df = pd.DataFrame(df_data)
    
    if all_technologies:
        tech_series = pd.Series(all_technologies)
        tech_counts = tech_series.value_counts()
    else:
        tech_counts = pd.Series()
    
    return df, tech_counts


def create_graphs(df, tech_counts):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç
    if not df.empty and 'salary_avg' in df.columns:
        plt.figure(figsize=(12, 8))
        salaries = df['salary_avg'].dropna()
        if len(salaries) > 0:
            plt.hist(salaries, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
            plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤')
            plt.xlabel('–ó–∞—Ä–ø–ª–∞—Ç–∞ (—Ä—É–±)')
            plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π')
            plt.grid(True, alpha=0.3)
            plt.savefig(f'graphs/exploratory_analysis/salary_distribution_{timestamp}.png', 
                       dpi=300, bbox_inches='tight')
            plt.close()
            print("‚úÖ –ì—Ä–∞—Ñ–∏–∫: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç")
    
    # 2. –¢–æ–ø —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
    if len(tech_counts) > 0:
        plt.figure(figsize=(14, 8))
        top_tech = tech_counts.head(15)
        colors = plt.cm.viridis(range(len(top_tech)))
        bars = plt.bar(range(len(top_tech)), top_tech.values, color=colors)
        plt.xticks(range(len(top_tech)), top_tech.index, rotation=45, ha='right')
        plt.title('–¢–æ–ø-15 –≤–æ—Å—Ç—Ä–µ–±–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π')
        plt.xlabel('–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π')
        plt.grid(True, alpha=0.3)
        
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{int(height)}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig(f'graphs/technologies/top_technologies_{timestamp}.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        print("‚úÖ –ì—Ä–∞—Ñ–∏–∫: –¢–æ–ø —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π")
    
    # 3. –ó–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –æ–ø—ã—Ç—É
    if not df.empty and 'salary_avg' in df.columns and 'experience' in df.columns:
        plt.figure(figsize=(12, 8))
        exp_salary = df.groupby('experience')['salary_avg'].mean().dropna()
        if len(exp_salary) > 0:
            colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']
            bars = exp_salary.plot(kind='bar', color=colors)
            plt.title('–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –æ–ø—ã—Ç—É —Ä–∞–±–æ—Ç—ã')
            plt.xlabel('–û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã')
            plt.ylabel('–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ (—Ä—É–±)')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            
            for i, v in enumerate(exp_salary):
                plt.text(i, v + 5000, f'{v:.0f}', ha='center', va='bottom')
            
            plt.savefig(f'graphs/exploratory_analysis/salary_by_experience_{timestamp}.png',
                       dpi=300, bbox_inches='tight')
            plt.close()
            print("‚úÖ –ì—Ä–∞—Ñ–∏–∫: –ó–∞—Ä–ø–ª–∞—Ç–∞ –ø–æ –æ–ø—ã—Ç—É")


def print_statistics(df, tech_counts):
    """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–Ω–∞–ª–∏–∑–∞."""
    print("\n" + "="*60)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê")
    print("="*60)
    
    if df.empty:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return
    
    print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –í—Å–µ–≥–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(df)}")
    
    if 'salary_avg' in df.columns:
        salary_data = df['salary_avg'].dropna()
        if len(salary_data) > 0:
            print(f"   –í–∞–∫–∞–Ω—Å–∏–π —Å –∑–∞—Ä–ø–ª–∞—Ç–æ–π: {len(salary_data)}")
            print(f"   –°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞: {salary_data.mean():,.0f} —Ä—É–±.")
            print(f"   –ú–µ–¥–∏–∞–Ω–Ω–∞—è –∑–∞—Ä–ø–ª–∞—Ç–∞: {salary_data.median():,.0f} —Ä—É–±.")
            print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: {salary_data.max():,.0f} —Ä—É–±.")
            print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: {salary_data.min():,.0f} —Ä—É–±.")
    
    print(f"\nüìä –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –û–ü–´–¢–£:")
    if 'experience' in df.columns:
        exp_counts = df['experience'].value_counts()
        for exp, count in exp_counts.items():
            percentage = (count / len(df)) * 100
            print(f"   {exp:<20} {count:>4} ({percentage:.1f}%)")
    
    print(f"\nüë• –¢–ò–ü–´ –ó–ê–ù–Ø–¢–û–°–¢–ò:")
    if 'employment' in df.columns:
        emp_counts = df['employment'].value_counts()
        for emp, count in emp_counts.items():
            percentage = (count / len(df)) * 100
            print(f"   {emp:<20} {count:>4} ({percentage:.1f}%)")
    
    if len(tech_counts) > 0:
        print(f"\nüèÜ –¢–û–ü-10 –¢–ï–•–ù–û–õ–û–ì–ò–ô:")
        for i, (tech, count) in enumerate(tech_counts.head(10).items(), 1):
            percentage = (count / len(df)) * 100 if len(df) > 0 else 0
            print(f"   {i:2d}. {tech:<20} {count:>4} ({percentage:.1f}%)")


def save_results(df, tech_counts):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º DataFrame
    if not df.empty:
        csv_file = f"data/vacancies_analysis_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"üíæ –î–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {csv_file}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π
    if len(tech_counts) > 0:
        tech_df = tech_counts.reset_index()
        tech_df.columns = ['Technology', 'Count']
        tech_df['Percentage'] = (tech_df['Count'] / len(df)) * 100 if len(df) > 0 else 0
        tech_csv = f"data/technologies_stats_{timestamp}.csv"
        tech_df.to_csv(tech_csv, index=False, encoding='utf-8-sig')
        print(f"üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤: {tech_csv}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞."""
    print("="*70)
    print("–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó HH.RU –° –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï–ú SCRAPY")
    print("="*70)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    if not check_dependencies():
        sys.exit(1)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    create_directories()
    
    # –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞
    print("\nüöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ï–†–ê...")
    try:
        from hh_scrapy_parser import run_parser
        vacancies = run_parser()
    except ImportError:
        print("‚ö† –ü–∞—Ä—Å–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª –¥–∞–Ω–Ω—ã—Ö...")
        if os.path.exists("programming_vacancies.json"):
            with open("programming_vacancies.json", "r", encoding="utf-8") as f:
                vacancies = json.load(f)
        else:
            print("‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            sys.exit(1)
    
    if not vacancies:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ!")
        sys.exit(1)
    
    print(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")
    
    # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•...")
    df, tech_counts = analyze_vacancies()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
    print("\nüé® –°–û–ó–î–ê–ù–ò–ï –ì–†–ê–§–ò–ö–û–í...")
    create_graphs(df, tech_counts)
    
    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print_statistics(df, tech_counts)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
    save_results(df, tech_counts)
    
    print("\n" + "="*70)
    print("‚úÖ –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
    print("="*70)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–∏
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:")
    print(f"   - –ü–∞–ø–∫–∞ 'graphs/' - –≥—Ä–∞—Ñ–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
    print(f"   - –ü–∞–ø–∫–∞ 'data/' - —Ç–∞–±–ª–∏—Ü—ã —Å –¥–∞–Ω–Ω—ã–º–∏")
    print(f"   - –§–∞–π–ª 'programming_vacancies.json' - –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")


if __name__ == "__main__":
    main()
